version: "3.8"
services:
  train:
    build:
      context: .
      args:
        - http_proxy=${http_proxy:-}
        - https_proxy=${https_proxy:-}
      tags:
        - ghcr.io/shoppal-ai/LLaVa:dev
    shm_size: "100gb"
    env_file: .env
    ports:
      - "${WEBUI_HOST_PORT:-7860}:7860"
    command:
      - deepspeed
      - /workspace/llava/train/train_mem.py
      - --deepspeed=./scripts/zero3.json 
      - --model_name_or_path=lmsys/vicuna-13b-v1.5 
      - --version=v1 
      - --data_path=${TRAIN_DATA_JSON} 
      - --image_folder=${TRAIN_IMAGE_ROOT}
      - --vision_tower=openai/clip-vit-large-patch14-336 
      - --pretrain_mm_mlp_adapter=${PRETRAIN_MM_BIN_FILE}
      - --mm_projector_type=mlp2x_gelu 
      - --mm_vision_select_layer=-2 
      - --mm_use_im_start_end=False 
      - --mm_use_im_patch_token=False 
      - --image_aspect_ratio=pad 
      - --group_by_modality_length=True 
      - --bf16=True 
      - --output_dir=${OUTPUT_DIR:-llava-v1.5-13b}
      - --num_train_epochs=1 
      - --per_device_train_batch_size=16 
      - --per_device_eval_batch_size=4 
      - --gradient_accumulation_steps=1 
      - --evaluation_strategy=no 
      - --save_strategy=steps 
      - --save_steps=50000 
      - --save_total_limit=1 
      - --learning_rate=2e-5 
      - --weight_decay=0. 
      - --warmup_ratio=0.03 
      - --lr_scheduler_type=cosine 
      - --logging_steps=1 
      - --tf32=True 
      - --model_max_length=2048 
      - --gradient_checkpointing=True 
      - --dataloader_num_workers=4 
      - --lazy_preprocess=True 
      - --report_to=wandb
    volumes:
      - /data0:/data0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all # if you want to use all gpus, just set count: all
              # device_ids: ['4'] # if you want to use specific gpus, set device_ids: [1, 2, 3]
